---
title: 1 = 0.9999...
date: 2016-09-01 00:32 UTC
tags:
  - philosophy>epistemology>math
  - philosophy>epistemology>logic
:summary: In mathematics it is proven that `1 = 0.9999...`. How is this so? But more importantly, in understanding how and why this is true, what can we glean about the nature of paradoxes? Let's explore.
image: 1-0-9.png
---

I saw a wonderful video recently on an odd fact in mathematics:

[![9.999... really is equal to 10 -- Mathologer](http://img.youtube.com/vi/SDtFBSjNmm0/0.jpg)](http://www.youtube.com/watch?v=SDtFBSjNmm0 "9.999... really is equal to 10")

In the video (from a channel I would heartily recommend), the presenter offers a proof that `10 = 9.9999...`. Here the ellipsis is quite important, as it communicates that the `9`s continue on _forever_, that is, to infinity. So, `9.9` followed by an infinite number of `9`s fully and simply equals `10`. I want to explore the proof for this fact and then move on to explore how this example of an infinity touching the finite might elucidate our understanding of paradoxes.

So, the video is concerned with `10 = 9.9999...`, but I want to take it down a notch and think about `1 = 0.9999...`. Borrowing the proof from the video, we can show that this identity statement is true relatively simply:

~~~shell
# Define the infinitely-repeating decimal as a variable
k = 0.9999...
# Multiply both sides of the equation by 10
10k = 9.9999...
# Subtract the larger portions by the smaller portions
(10k - k) = (9.9999... - 0.9999...)
# Since the infinitely-repeating decimals are both infinitely long,
# subtraction cancels them out
9k = 9
# Divide both sides of the equation by 9
k = 1
# Replace k with our original identity
1 = 0.9999...
~~~

Now, this proof may perhaps feel a bit fishy to you; you may think that we are mathematically cheating somewhere, but I can promise you that every single step is totally valid. And if every step is totally valid, then the conclusion is valid. But how can this be and what does this mean?

This "problem", this seeming incongruity, arises because we have a hard time grappling with infinity. To put it another way, we underestimate the weight of that ellipsis. So let's dig into that ellipsis a bit. What does `0.9999...` really mean, really represent? Well, we all remember from elementary school that decimals can also be represented by fractions, so let's try to represent this decimal by a fraction. Unfortunately, there is no simple fraction to represent this number (like `0.3333...` being representable by \\(\frac{1}{3}\\)). However, we can break this decimal down. We know that `0.9` is simply \\(\frac{9}{10}\\), and `0.09` is \\(\frac{9}{100}\\), and `0.009` is \\(\frac{9}{1000}\\) and so on. We also know that `0.9 + 0.09 + 0.009 = 0.999`. So, we could represent `0.9999...` fractionally as:

$$\frac{9}{10} + \frac{9}{100} + \frac{9}{1000} + \frac{9}{10000} + \ldots$$

In mathematics, this is called an _infinite sum_ or an _infinite series_; we are adding terms together to infinity. If you recall from your high school math class, you can represent an infinite sum with what is called **[sigma notation](https://en.wikipedia.org/wiki/Summation#Capital-sigma_notation)**, and our infinite sum above can be represented as:

$$\sum_{n=1}^{\infty} \frac{9}{10^n}$$

This is simply a more concise way of writing the larger sum of the fractions above.

Infinite sums are truly fascinating, and I hope to write more about them in the future, but for now I want to focus on one characteristic in particular. All infinite sums fit into one of two categories: _convergent_ or _divergent_. Now, these are math-jargon terms that mean relatively simple things. An infinite sum is _convergent_ if it converges on a finite number. The language you might remember from your calculus class is that the _limit_ of the infinite sum _approaches_ a finite number. So, a _convergent infinite sum_ is an infinity that touches the finite. In contrast, a _divergent infinite sum_ is one that has no limit, one that grows to infinity.[^2] A stock example is

$$\sum_{n=1}^{\infty} \frac{1}{n}$$

or

$$1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \ldots$$

This is an infinite sum that approaches infinity, that is, it _diverges_, it does not have a finite limit, it is unbounded.

Returning to our infinite sum, we have enough context now to see that saying `1 = 0.9999...` is really just one way of saying that the summation of \\(\frac{9}{10^n}\\) as `n` goes from 1 to infinity is a convergent infinite sum that converges on 1.

Ok, so that was a fun romp through one fascinating branch of mathematics, but all we really did was gain enough context to state the "odd fact" in more precise mathematical language. What's the point? I stated at the beginning that I was fascinated by some of the general ramifications of infinity touching the finite. What we have with convergent infinite sums are well-studied mathematical examples of precisely this phenomenon. And I find them so fascinating because they offer glimpses at some of the issues we face when thinking about infinity. However, they also show us that we _can_ think well about infinity.

The implication I'd like to explore a bit now is that paradoxes abound when the infinite colliding with the finite. On the one hand, it is quite clear that `1` _does not equal_ `0.9999...` for the simple reason that `1` is a finite integer and `0.9999...` is an infinite series. If _equality_ is _categorical identity_, then `1` and `0.9999...` are not equal. On the other hand, this whole post has shown that `1` _does equal_ `0.9999...`. If _equality_ is _referrential identity_, then `1` and `0.9999...` are equal. Now, note that I call this a paradox and not an antinomy. I want to define these two terms clearly and distinguish them. In my parlance, a **paradox** is a _seeming_ contradiction, while an **antinomy** is an _actual_ contradiction; that is, a paradox is resolvable and an antinomy is not.

It is important, however, to note that resolving a paradox _does not_ mean that one side "wins" and the other "loses", that one proposition is "right" and the other is "wrong"; instead, it means that we can rationally make sense of the difference between the two propositions. This is why I used the if-then statements above. It is not that one of the propositions is "right" or "wrong", it is that we can enumerate the conditions under which each one would be "right" and the other "wrong". An antinomy does not submit itself to such enumeration; we cannot articulate the conditions under which one side is "right" and the other is "wrong". So, if I were to abstract out my definitions of _paradoxes_ and _antinomies_, I would describe them thusly:

> A paradox is composed of a proposition (`P`) and its negation (`not-P`) such that the conditionals "if `conditions for P`, then `P`" and "if `conditions for not-P`, then `not-P`" are both true, and thus the conjunction "if `conditions for P`, then `P` and if `conditions for not-P`, then `not-P`" is also true.


> An antinomy is composed of a proposition (`P`) and its negation (`not-P`) such that there are no conditions for `P` or `not-P` and the conjunction "`P` and `not-P`" is true.[^1]

I believe that paradoxes run deep in our world. I have written earlier on my neologism ["conjunctive binarism"](http://fractaledmind.com/articles/conjunctive-binarism), a view that truth is probably most closely articulated as "the proposition `P` and its contradiction `¬P` are _kinda_ both true". After exploring a convergent infinite sums, I feel that this definition of paradoxes more properly expresses my view of what this "kinda" maps to. So, `1 = 0.9999... and 1 != 0.9999...` is a "conjunctive binary". If we express it in the form of the paradox explained above, we would express that proposition as "if equality means referential indentiy, then 1 = 0.9999... and if equality means categorical identity, then 1 != 0.9999...". Going one step further, I would now define a conjunctive binary as a compound proposition of that form ("if `conditions for P`, then `P` and if `conditions for not-P`, then `not-P`").

[^1]: There is a branch of epistemology that believes such conjections do exist and calls them "dialetheias".
[^2]:
    Well, that is not properly technically true, as there are some divergent series that do not tend to infinity, but are also clearly not convergent. Take `1 − 1 + 1 − 1 + ⋯`. This is the so-called [Grandi's series](https://en.wikipedia.org/wiki/Grandi%27s_series), and if you attempt to resolve it using partial sums, you will quickly see that the value ocillates between `1` (when the number of terms in the partial sum is odd) and `0` (when the number of terms in the partial sum is even). However, modern mathematics defines its sum as \\(\frac{1}{2}\\), which is a finite term (thus it would appear to "converge" on \\(\frac{1}{2}\\)). Thus, this series would appear to have two conclusions:

      1. The series 1 − 1 + 1 − 1 + ⋯ has no sum.
      2. Its sum should be \\(\frac{1}{2}\\).

    I find this infinite series fascinating, and may very well write it about at some point as well.
